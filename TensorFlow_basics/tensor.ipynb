{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yuanshuai\\AppData\\Local\\anaconda3\\envs\\tensorflow2\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#张量是具有统一类型（称为 dtype）的多维数组.您可以在 tf.dtypes.DType 中查看所有支持的 dtypes。\n",
    "#如果您熟悉 NumPy，就会知道张量与 np.arrays 有一定的相似性。\n",
    "#就像 Python 数值和字符串一样，所有张量都是不可变的：永远无法更新张量的内容，只能创建新的张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#下面是一个“标量”（或称“0 秩”张量）。标量包含单个值，但没有“轴”。\n",
    "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#“向量”（或称“1 秩”张量）就像一个值列表。向量有 1 个轴：\n",
    "# Let's make this a float tensor.\n",
    "rank_1_tensor = tf.constant([2.0,3.0,4.0])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]], shape=(3, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "#“矩阵”（或称“2 秩”张量）有 2 个轴：\n",
    "# If you want to be specific, you can set the dtype (see below) at creation time\n",
    "rank_2_tensor = tf.constant(\n",
    "    [[1,2],\n",
    "    [3,4],\n",
    "    [5,6]],dtype=tf.float16)\n",
    "\n",
    "print(rank_2_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "#张量的轴可能更多，下面是一个包含 3 个轴的张量：\n",
    "# There can be an arbitrary number of\n",
    "# axes (sometimes called \"dimensions\")\n",
    "rank_3_tensor = tf.constant(\n",
    "    [\n",
    "        [[1,2],[3,4]],\n",
    "        [[5,6],[7,8]],\n",
    "        ], dtype=tf.int16\n",
    ")\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#通过使用 np.array 或 tensor.numpy 方法，您可以将张量转换为 NumPy 数组：\n",
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [10 12]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[-4 -4]\n",
      " [-4 -4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 5 12]\n",
      " [21 32]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]], shape=(2, 2), dtype=float64) \n",
      "\n",
      "tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#张量通常包含浮点型和整型数据，但是还有许多其他数据类型，包括：\n",
    "#复杂的数值\n",
    "#字符串\n",
    "#您可以对张量执行基本数学运算，包括加法、逐元素乘法和矩阵乘法。\n",
    "\n",
    "a = tf.constant([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "],dtype=tf.int32)\n",
    "\n",
    "b = tf.constant([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "],dtype=tf.int32)\n",
    "\n",
    "\n",
    "print(tf.add(a,b),\"\\n\")\n",
    "print(tf.subtract(a,b),\"\\n\")\n",
    "print(tf.multiply(a,b),\"\\n\")\n",
    "print(tf.divide(a,b),\"\\n\")\n",
    "print(tf.matmul(a,b),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32) \n",
      "\n",
      "tf.Tensor([ 5. 10.], shape=(2,), dtype=float32) \n",
      "\n",
      "tf.Tensor([ 6.  7.  8.  9. 10.], shape=(5,), dtype=float32) \n",
      "\n",
      "tf.Tensor([1 1 1 1 1], shape=(5,), dtype=int64) \n",
      "\n",
      "tf.Tensor([4 4], shape=(2,), dtype=int64) \n",
      "\n",
      "tf.Tensor(\n",
      "[[0.01165623 0.03168492 0.08612853 0.23412165 0.63640857]\n",
      " [0.01165623 0.03168492 0.08612853 0.23412165 0.63640857]], shape=(2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#各种运算都可以使用张量。\n",
    "#tf.reduce_max 是 TensorFlow 中的一个函数，用于计算张量（tensor）中的最大值。它可以沿着张量的一个或多个维度进行操作。\n",
    "a = tf.constant([\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10]\n",
    "],dtype=tf.float32)\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(a),\"\\n\") #全局最大值\n",
    "print(tf.reduce_max(a,axis=1),\"\\n\") #1轴/行最大值\n",
    "print(tf.reduce_max(a,axis=0),\"\\n\") #0轴/列最大值\n",
    "\n",
    "# Find the index of the largest value\n",
    "print(tf.math.argmax(a,0),\"\\n\") #每列最大值索引\n",
    "print(tf.math.argmax(a,1),\"\\n\") #行最大值索引\n",
    "\n",
    "# Compute the softmax\n",
    "#tf.nn.softmax 函数用于计算张量中每个元素的 softmax 激活值。\n",
    "#Softmax 函数将输入的张量转换为一个新的张量，其中每个元素的取值范围在 0 到 1 之间，并且所有元素之和为 1。这使得 softmax 激活函数特别适合用于多分类问题中的输出层，其中每个输出节点表示一个类别的概率。\n",
    "print(tf.nn.softmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##张量有形状。下面是几个相关术语：\n",
    "\n",
    "#形状：张量的每个轴的长度（元素数量）。\n",
    "#秩：张量轴数。标量的秩为 0，向量的秩为 1，矩阵的秩为 2。\n",
    "#轴或维度：张量的一个特殊维度。\n",
    "#大小：张量的总项数，即形状矢量元素的乘积\n",
    "#注：虽然您可能会看到“二维张量”之类的表述，但 2 秩张量通常并不是用来描述二维空间。\n",
    "\n",
    "rank_4_tensor = tf.zeros([3,2,4,5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of axes: 4\n",
      "Shape of tensor: (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 3\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5):  120\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32) \n",
      "\n",
      "tf.Tensor([3 2 4 5], shape=(4,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#但请注意，Tensor.ndim 和 Tensor.shape 特性不返回 Tensor 对象。如果您需要 Tensor，请使用 tf.rank 或 tf.shape 函数。这种差异不易察觉，但在构建计算图时（稍后）可能非常重要。\n",
    "print(tf.rank(rank_4_tensor),'\\n')\n",
    "print(tf.shape(rank_4_tensor),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#虽然通常用索引来指代轴，但是您始终要记住每个轴的含义。轴一般按照从全局到局部的顺序进行排序：首先是批次轴，随后是空间维度，最后是每个位置的特征。这样，在内存中，特征向量就会位于连续的区域。\n",
    "# https://tensorflow.google.cn/guide/tensor?hl=zh-cn   结合2个图理解\n",
    "# 3 2 4 5\n",
    "# 3 - Batch\n",
    "# 2 - Height\n",
    "# 4 - Width\n",
    "# 5 - Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
